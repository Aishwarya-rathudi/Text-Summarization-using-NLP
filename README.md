# ğŸ“˜ End-to-End Text Summarizer Project using NLP  

ğŸ“Œ Project Description

This project implements an NLP-based Text Summarizer that takes long text passages and generates concise summaries. It is built using Hugging Face Transformers and deployed with a complete MLOps workflow including modular pipelines, configuration management, and cloud deployment via AWS with CI/CD pipelines.
The project is structured into stages (pipelines) for data transformation, model training, and prediction, making it highly scalable, reproducible, and production-ready.

---

## flowchart TD

    A[ğŸ“‚ Raw Data] --> B[ğŸ”„ Data Transformation<br>(ğŸ“ Tokenization, Padding)]
    
    B --> C[ğŸ§  Model Training<br>(âš™ï¸ Fine-tune Transformer Model)]
    
    C --> D[ğŸ’¾ Save Model Artifacts]
    
    D --> E[âš¡ Prediction Pipeline<br>(âœ‚ï¸ Summarization Inference)]
    
    E --> F[ğŸ³ Dockerized App]
    
    F --> G[â˜ï¸ AWS Deployment<br>(EC2 + ECR)]
    
    G --> H[ğŸ¤– CI/CD with GitHub Actions]

## ğŸ”„ Workflows  

1. Update `config.yaml`
     
2. Update `params.yaml`
   
3. Update entity
   
4. Update the configuration manager in `src/config`
    
5. Update the components
    
6. Update the pipeline
      
7. Update the `main.py`
     
8. Update the `app.py`  

---
## ğŸ›  Tech Stack

Programming Language: Python

NLP Library: Hugging Face Transformers (AutoTokenizer, pipeline)

Deep Learning: PyTorch / TensorFlow backend (via Transformers)

Configuration Management: YAML (config.yaml, params.yaml)

Logging: Custom logging utilities (logger)

Deployment: AWS EC2, ECR, Docker, GitHub Actions

## ğŸš€ Key Features

End-to-End Modular Pipelines â†’ Easy to train, transform, and deploy models.

Config-Driven Workflow â†’ Centralized parameters for flexible experimentation.

Prediction API â†’ Real-time summarization via a PredictionPipeline.

MLOps Ready â†’ Integrated with CI/CD pipelines, Docker, AWS for deployment.

Reproducibility â†’ Experiment tracking using configurations and modular design.

# â˜ï¸ AWS CICD Deployment with GitHub Actions  

### ğŸ”¹ 1. Login to AWS Console  

### ğŸ”¹ 2. Create IAM User for Deployment  

**With specific access:**  
- **EC2 Access** â†’ Virtual machine hosting environment
  
- **ECR Access** â†’ Elastic Container Registry for storing Docker images  

**Deployment Description:**  
1. Build Docker image of the source code
    
2. Push Docker image to ECR
   
3. Launch EC2 instance
   
4. Pull the image from ECR into EC2
   
5. Run the Docker image on EC2  

**IAM Policies Required:**  
- `AmazonEC2ContainerRegistryFullAccess`
  
- `AmazonEC2FullAccess`  

---

### ğŸ”¹ 3. Create ECR Repository  

- Example URI:


---

### ğŸ”¹ 4. Create EC2 Machine (Ubuntu)  

Launch an Ubuntu EC2 instance to host the application.  

---

### ğŸ”¹ 5. Install Docker in EC2  

```bash
# Optional

sudo apt-get update -y

sudo apt-get upgrade -y

# Required
curl -fsSL https://get.docker.com -o get-docker.sh

sudo sh get-docker.sh

sudo usermod -aG docker ubuntu

newgrp docker

###ğŸ”¹ 6. Configure EC2 as Self-Hosted Runner

Navigate to:

GitHub Repository > Settings > Actions > Runners > New self-hosted runner

Select OS (Ubuntu) â†’ Run setup commands provided by GitHub.

###ğŸ”¹ 7. Setup GitHub Secrets

Add the following secrets in GitHub â†’ Settings â†’ Secrets and variables â†’ Actions:

AWS_ACCESS_KEY_ID = <your-access-key>

AWS_SECRET_ACCESS_KEY = <your-secret-key>

AWS_REGION = us-east-1

AWS_ECR_LOGIN_URI = 566373416292.dkr.ecr.ap-south-1.amazonaws.com

ECR_REPOSITORY_NAME = simple-app  

